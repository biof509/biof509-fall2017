{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 - Assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasification Exercises\n",
    "\n",
    "1. Load the handwritten digits dataset and choose an appropriate metric\n",
    "2. Divide the data into a training and test dataset\n",
    "3. Build a RandomForestClassifier on the training dataset, using cross-validation to evaluate performance\n",
    "4. Choose another classification algorithm and apply it to the handwritten digits dataset. \n",
    "5. Use grid search to find the optimal parameters for the chosen algorithm.\n",
    "6. Comparing the true values with the predictions from the best model identify the numbers that are most commonly confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 - Load the handwritten digits dataset and choose an appropriate metric\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "digits = sklearn.datasets.load_digits()\n",
    "\n",
    "# X - how digits are handwritten\n",
    "X = digits['data']\n",
    "\n",
    "# y - what these digits actually are\n",
    "y = digits['target']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(\"MSE: example for digit 0 compared to another example for digit 0\", mean_squared_error(X[0], X[10]))\n",
    "print(\"MSE: example for digit 0 compared to examle for digit 4\", mean_squared_error(X[0], X[400]))\n",
    "\n",
    "print(y[10])\n",
    "plt.imshow(X[20].reshape((8,8)),  cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics for more details.\n",
    "\n",
    "A balanced F1 score combining precision and recall is a good default performance measure for binary classifiers. However, our problem is multiclass - where we have 10 classes, one for each digit. In extending a binary metric to multiclass or multilabel problems, the data is treated as a collection of binary problems, one for each class.\n",
    "\n",
    "There are then a number of ways to average binary metric calculations across the set of classes, each of which may be useful in some scenario. Where available, you should select among these using the average parameter.\n",
    "\n",
    "\"macro\" simply calculates the mean of the binary metrics, giving equal weight to each class. In problems where infrequent classes are nonetheless important, macro-averaging may be a means of highlighting their performance. On the other hand, the assumption that all classes are equally important is often untrue, such that macro-averaging will over-emphasize the typically low performance on an infrequent class.\n",
    "\n",
    "Thus if we make sure that each digit is represented by approximately equal number of samples, the performance of a classifier will be best evaluated using F1 with macro averaging across the classes. Stratified Kfold or Stratified train_test_split can be used to make sure each class gets an approximately equal number of samples in a random split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 - Divide the data into a training and test dataset\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 - Build a RandomForestClassifier on the training dataset, using cross-validation to evaluate performance\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 - Choose another classification algorithm and apply it to the digits dataset. \n",
    "\n",
    "# Let us consider a KNN classifier with 5 nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5 - Use grid search to find the optimal parameters for the chosen algorithm.\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 6 - Comparing the true values with the predictions from the best model identify the numbers that are most commonly confused.\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
